{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "860fe2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library and some pre-installed modules\n",
    "import os\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd310426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the root directory of the project as the working directory\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36379e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/darlanmnunes/Dev/DSc_git/PhD_Thesis_Step3_OSM_Toponyms'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get current working directory\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e705ee5",
   "metadata": {},
   "source": [
    "## Import the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b5adb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.processar_com_ohsome' from '/Users/darlanmnunes/Dev/DSc_git/PhD_Thesis_Step3_OSM_Toponyms/src/processar_com_ohsome.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload the utils and processar_com_overpass modules to ensure any changes are reflected\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "import src.utils as utils\n",
    "import src.processar_com_overpass as processar_com_overpass\n",
    "import src.processar_com_ohsome as processar_com_ohsome\n",
    "\n",
    "importlib.reload(utils)\n",
    "importlib.reload(processar_com_overpass)\n",
    "importlib.reload(processar_com_ohsome)\n",
    "\n",
    "#Alternativa\n",
    "#importlib.reload(sys.modules[\"src.utils\"])\n",
    "#importlib.reload(sys.modules[\"src.processar_com_overpass\"])\n",
    "#importlib.reload(sys.modules[\"src.processar_com_ohsome\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7671b8df",
   "metadata": {},
   "source": [
    "## Retrieving data from OpenStreetMap using APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203e6467",
   "metadata": {},
   "source": [
    "### Define ET-EDGV class dictionary with respective OSM tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0bb9e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edif_ensino': [('amenity', 'school'),\n",
       "  ('amenity', 'university'),\n",
       "  ('building', 'school'),\n",
       "  ('amenity', 'kindergarten')],\n",
       " 'edif_saude': [('amenity', 'hospital'),\n",
       "  ('amenity', 'clinic'),\n",
       "  ('building', 'hospital'),\n",
       "  ('amenity', 'doctors'),\n",
       "  ('amenity', 'dentist'),\n",
       "  ('healthcare', '*')],\n",
       " 'edif_desenv_social': [('amenity', 'social_facility'),\n",
       "  ('building', 'public'),\n",
       "  ('social_facility', '*')],\n",
       " 'edif_constr_lazer': [('leisure', 'park'),\n",
       "  ('leisure', 'sports_centre'),\n",
       "  ('leisure', 'stadium'),\n",
       "  ('amenity', 'theatre'),\n",
       "  ('amenity', 'library'),\n",
       "  ('amenity', 'community_centre'),\n",
       "  ('amenity', 'arts_centre'),\n",
       "  ('amenity', 'planetarium'),\n",
       "  ('building', 'grandstand'),\n",
       "  ('building', 'stadium'),\n",
       "  ('tourism', 'museum')],\n",
       " 'edif_pub_civil': [('building', 'public'),\n",
       "  ('amenity', 'townhall'),\n",
       "  ('office', 'government')],\n",
       " 'edif_turistica': [('tourism', 'attraction'),\n",
       "  ('tourism', 'artwork'),\n",
       "  ('tourism', 'viewpoint'),\n",
       "  ('amenity', 'fountain'),\n",
       "  ('building', 'hotel')],\n",
       " 'edif_metro_ferroviaria': [('railway', 'station'),\n",
       "  ('railway', 'halt'),\n",
       "  ('building', 'train_station'),\n",
       "  ('public_transport', 'station')]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Novo dicionário de classes ET-EDGV com respectivas tags OSM\n",
    "classe_et_edgv_to_tags = {\n",
    "    'edif_ensino': [\n",
    "        ('amenity', 'school'), ('amenity', 'university'),\n",
    "        ('building', 'school'), ('amenity', 'kindergarten')\n",
    "    ],\n",
    "    'edif_saude': [\n",
    "        ('amenity', 'hospital'), ('amenity', 'clinic'),\n",
    "        ('building', 'hospital'), ('amenity', 'doctors'),\n",
    "        ('amenity', 'dentist'), ('healthcare', '*')\n",
    "    ],\n",
    "    'edif_desenv_social': [\n",
    "        ('amenity', 'social_facility'), ('building', 'public'),\n",
    "        ('social_facility', '*')\n",
    "    ],\n",
    "    'edif_constr_lazer': [\n",
    "        ('leisure', 'park'), ('leisure', 'sports_centre'),\n",
    "        ('leisure', 'stadium'), ('amenity', 'theatre'),\n",
    "        ('amenity', 'library'), ('amenity', 'community_centre'),\n",
    "        ('amenity', 'arts_centre'), ('amenity', 'planetarium'),\n",
    "        ('building', 'grandstand'), ('building', 'stadium'),\n",
    "        ('tourism', 'museum')\n",
    "    ],\n",
    "    'edif_pub_civil': [\n",
    "        ('building', 'public'), ('amenity', 'townhall'),\n",
    "        ('office', 'government')\n",
    "    ],\n",
    "    'edif_turistica': [\n",
    "        ('tourism', 'attraction'), ('tourism', 'artwork'),\n",
    "        ('tourism', 'viewpoint'), ('amenity', 'fountain'),\n",
    "        ('building', 'hotel')\n",
    "    ],\n",
    "    'edif_metro_ferroviaria': [\n",
    "        ('railway', 'station'), ('railway', 'halt'),\n",
    "        ('building', 'train_station'), ('public_transport', 'station')\n",
    "    ]\n",
    "}\n",
    "classe_et_edgv_to_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f64442c",
   "metadata": {},
   "source": [
    "### Step 7 - Retrieval of the last toponyms by the most recent feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cdb58d",
   "metadata": {},
   "source": [
    "#### PostGIS - Open the database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b10b2d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conexão ao Banco PostGIS\n",
    "import psycopg2\n",
    "\n",
    "# Function to load database credentials from a text file\n",
    "def load_credentials_from_txt(file_path):\n",
    "    credentials = {}\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                if '=' in line:\n",
    "                    key, value = line.strip().split('=', 1)\n",
    "                    credentials[key.strip()] = value.strip()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Arquivo de credenciais não encontrado: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao ler credenciais: {e}\")\n",
    "    return credentials\n",
    "\n",
    "def connect_to_postgis(txt_path='configs/db_credentials.txt'):\n",
    "    creds = load_credentials_from_txt(txt_path)\n",
    "\n",
    "    required_keys = ['DB_NAME', 'DB_USER', 'DB_PASSWORD', 'DB_HOST', 'DB_PORT']\n",
    "    if not all(k in creds for k in required_keys):\n",
    "        print(\"Credenciais incompletas no arquivo de configuração.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=creds['DB_NAME'],\n",
    "            user=creds['DB_USER'],\n",
    "            password=creds['DB_PASSWORD'],\n",
    "            host=creds['DB_HOST'],\n",
    "            port=creds['DB_PORT']\n",
    "        )\n",
    "        print(\"Conexão ao PostGIS estabelecida com sucesso!\")\n",
    "        return conn\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Erro ao conectar ao PostGIS: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5ec3843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexão ao PostGIS estabelecida com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Open the database connection\n",
    "conn = connect_to_postgis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7004a37a",
   "metadata": {},
   "source": [
    "#### Filter grid cells from the database with name_ratio > 0\n",
    "\n",
    " * Pré-filtragem SQL\n",
    " * Garantir que pelo menos uma classe tem name_ratio > 0 para cada célula da grade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "685267f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch valid grid cells from the database\n",
    "from shapely import wkt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "def fetch_geometries_psycopg2(conn, classe_et_edgv_to_tags, table_name):\n",
    "    \"\"\"\n",
    "    Recupera geometrias do PostGIS com base nos filtros name_ratio > 0 usando psycopg2.\n",
    "    Retorna um GeoDataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Garante que qualquer erro anterior seja limpo\n",
    "        conn.rollback()\n",
    "\n",
    "        # Monta cláusula WHERE\n",
    "        where_clause = \" OR \".join([\n",
    "            f\"step1_consolidado_{classe}_name_ratio > 0\" for classe in classe_et_edgv_to_tags\n",
    "        ])\n",
    "\n",
    "        query = f\"\"\"\n",
    "            SELECT *, ST_AsText(geom) AS wkt_geom\n",
    "            FROM public.{table_name}\n",
    "            WHERE {where_clause}\n",
    "        \"\"\"\n",
    "\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(query)\n",
    "            colnames = [desc[0] for desc in cur.description]\n",
    "            rows = cur.fetchall()\n",
    "\n",
    "        # Monta DataFrame\n",
    "        df = pd.DataFrame(rows, columns=colnames)\n",
    "\n",
    "        # Converte geometria WKT em shapely\n",
    "        df[\"geometry\"] = df[\"wkt_geom\"].apply(wkt.loads)\n",
    "        gdf = gpd.GeoDataFrame(df.drop(columns=[\"wkt_geom\"]), geometry=\"geometry\")\n",
    "\n",
    "        # Define CRS padrão\n",
    "        gdf.set_crs(epsg=4674, inplace=True)\n",
    "\n",
    "        print(f\"Consulta retornou {len(gdf)} registros.\")\n",
    "        return gdf\n",
    "\n",
    "    except psycopg2.Error as e:\n",
    "        conn.rollback()\n",
    "        print(\"Erro ao executar a consulta SQL:\")\n",
    "        print(e.pgerror)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "027cfb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consulta retornou 2265 registros.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>geom</th>\n",
       "      <th>fid</th>\n",
       "      <th>POP10</th>\n",
       "      <th>step1_consolidado_edif_ensino_total_count</th>\n",
       "      <th>step1_consolidado_edif_ensino_name_count</th>\n",
       "      <th>step1_consolidado_edif_ensino_name_ratio</th>\n",
       "      <th>step1_consolidado_edif_saude_total_count</th>\n",
       "      <th>step1_consolidado_edif_saude_name_count</th>\n",
       "      <th>step1_consolidado_edif_saude_name_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>step6_consolidado_edif_metro_ferroviaria_sigmoid_pct_erro</th>\n",
       "      <th>step6_consolidado_edif_metro_ferroviaria_sigmoid_a</th>\n",
       "      <th>step6_consolidado_edif_metro_ferroviaria_sigmoid_b</th>\n",
       "      <th>step6_consolidado_edif_metro_ferroviaria_sigmoid_c</th>\n",
       "      <th>step6_consolidado_edif_metro_ferroviaria_sigmoid_d</th>\n",
       "      <th>step6_consolidado_edif_metro_ferroviaria_inflexao_idx</th>\n",
       "      <th>step6_consolidado_edif_metro_ferroviaria_inflexao_data</th>\n",
       "      <th>step6_consolidado_edif_metro_ferroviaria_sigmoid_fit_overflow</th>\n",
       "      <th>step6_consolidado_edif_metro_ferroviaria_dias_desde_inflexao</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200ME60338N90882</td>\n",
       "      <td>0106000020421200000100000001030000000100000005...</td>\n",
       "      <td>1</td>\n",
       "      <td>345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTIPOLYGON (((-44.06371 -19.97798, -44.06378...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200ME60346N90862</td>\n",
       "      <td>0106000020421200000100000001030000000100000005...</td>\n",
       "      <td>8</td>\n",
       "      <td>202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTIPOLYGON (((-44.05535 -19.99568, -44.05542...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200ME60348N90862</td>\n",
       "      <td>0106000020421200000100000001030000000100000005...</td>\n",
       "      <td>9</td>\n",
       "      <td>525</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTIPOLYGON (((-44.05343 -19.99561, -44.05350...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200ME60346N90864</td>\n",
       "      <td>0106000020421200000100000001030000000100000005...</td>\n",
       "      <td>11</td>\n",
       "      <td>349</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTIPOLYGON (((-44.05542 -19.99388, -44.05548...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200ME60348N90864</td>\n",
       "      <td>0106000020421200000100000001030000000100000005...</td>\n",
       "      <td>12</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTIPOLYGON (((-44.05350 -19.99382, -44.05356...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                               geom  fid  \\\n",
       "0  200ME60338N90882  0106000020421200000100000001030000000100000005...    1   \n",
       "1  200ME60346N90862  0106000020421200000100000001030000000100000005...    8   \n",
       "2  200ME60348N90862  0106000020421200000100000001030000000100000005...    9   \n",
       "3  200ME60346N90864  0106000020421200000100000001030000000100000005...   11   \n",
       "4  200ME60348N90864  0106000020421200000100000001030000000100000005...   12   \n",
       "\n",
       "   POP10  step1_consolidado_edif_ensino_total_count  \\\n",
       "0    345                                        0.0   \n",
       "1    202                                        1.0   \n",
       "2    525                                        1.0   \n",
       "3    349                                        1.0   \n",
       "4    500                                        0.0   \n",
       "\n",
       "   step1_consolidado_edif_ensino_name_count  \\\n",
       "0                                       0.0   \n",
       "1                                       1.0   \n",
       "2                                       1.0   \n",
       "3                                       1.0   \n",
       "4                                       0.0   \n",
       "\n",
       "   step1_consolidado_edif_ensino_name_ratio  \\\n",
       "0                                       0.0   \n",
       "1                                     100.0   \n",
       "2                                     100.0   \n",
       "3                                     100.0   \n",
       "4                                       0.0   \n",
       "\n",
       "   step1_consolidado_edif_saude_total_count  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       0.0   \n",
       "4                                       0.0   \n",
       "\n",
       "   step1_consolidado_edif_saude_name_count  \\\n",
       "0                                      0.0   \n",
       "1                                      0.0   \n",
       "2                                      0.0   \n",
       "3                                      0.0   \n",
       "4                                      0.0   \n",
       "\n",
       "   step1_consolidado_edif_saude_name_ratio  ...  \\\n",
       "0                                      0.0  ...   \n",
       "1                                      0.0  ...   \n",
       "2                                      0.0  ...   \n",
       "3                                      0.0  ...   \n",
       "4                                      0.0  ...   \n",
       "\n",
       "   step6_consolidado_edif_metro_ferroviaria_sigmoid_pct_erro  \\\n",
       "0                                                NaN           \n",
       "1                                                NaN           \n",
       "2                                                NaN           \n",
       "3                                                NaN           \n",
       "4                                                NaN           \n",
       "\n",
       "   step6_consolidado_edif_metro_ferroviaria_sigmoid_a  \\\n",
       "0                                                NaN    \n",
       "1                                                NaN    \n",
       "2                                                NaN    \n",
       "3                                                NaN    \n",
       "4                                                NaN    \n",
       "\n",
       "   step6_consolidado_edif_metro_ferroviaria_sigmoid_b  \\\n",
       "0                                                NaN    \n",
       "1                                                NaN    \n",
       "2                                                NaN    \n",
       "3                                                NaN    \n",
       "4                                                NaN    \n",
       "\n",
       "   step6_consolidado_edif_metro_ferroviaria_sigmoid_c  \\\n",
       "0                                                NaN    \n",
       "1                                                NaN    \n",
       "2                                                NaN    \n",
       "3                                                NaN    \n",
       "4                                                NaN    \n",
       "\n",
       "   step6_consolidado_edif_metro_ferroviaria_sigmoid_d  \\\n",
       "0                                                NaN    \n",
       "1                                                NaN    \n",
       "2                                                NaN    \n",
       "3                                                NaN    \n",
       "4                                                NaN    \n",
       "\n",
       "   step6_consolidado_edif_metro_ferroviaria_inflexao_idx  \\\n",
       "0                                                NaN       \n",
       "1                                                NaN       \n",
       "2                                                NaN       \n",
       "3                                                NaN       \n",
       "4                                                NaN       \n",
       "\n",
       "   step6_consolidado_edif_metro_ferroviaria_inflexao_data  \\\n",
       "0                                               None        \n",
       "1                                               None        \n",
       "2                                               None        \n",
       "3                                               None        \n",
       "4                                               None        \n",
       "\n",
       "   step6_consolidado_edif_metro_ferroviaria_sigmoid_fit_overflow  \\\n",
       "0                                               None               \n",
       "1                                               None               \n",
       "2                                               None               \n",
       "3                                               None               \n",
       "4                                               None               \n",
       "\n",
       "   step6_consolidado_edif_metro_ferroviaria_dias_desde_inflexao  \\\n",
       "0                                                NaN              \n",
       "1                                                NaN              \n",
       "2                                                NaN              \n",
       "3                                                NaN              \n",
       "4                                                NaN              \n",
       "\n",
       "                                            geometry  \n",
       "0  MULTIPOLYGON (((-44.06371 -19.97798, -44.06378...  \n",
       "1  MULTIPOLYGON (((-44.05535 -19.99568, -44.05542...  \n",
       "2  MULTIPOLYGON (((-44.05343 -19.99561, -44.05350...  \n",
       "3  MULTIPOLYGON (((-44.05542 -19.99388, -44.05548...  \n",
       "4  MULTIPOLYGON (((-44.05350 -19.99382, -44.05356...  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the valid grid cell (name_ratio>0)from the database using psycopg2\n",
    "gdf_cells_valid = fetch_geometries_psycopg2(conn, classe_et_edgv_to_tags, table_name=\"steps_merged_1to6\")\n",
    "display(gdf_cells_valid.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b45a602d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edif_ensino': 7,\n",
       " 'edif_saude': 1,\n",
       " 'edif_desenv_social': 0,\n",
       " 'edif_constr_lazer': 34,\n",
       " 'edif_pub_civil': 1,\n",
       " 'edif_turistica': 1,\n",
       " 'edif_metro_ferroviaria': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of valid cells (name_ratio > 0) for each class\n",
    "valid_counts = {\n",
    "    classe: (gdf_cells_valid[f\"step1_consolidado_{classe}_name_ratio\"] > 0).sum()\n",
    "    for classe in classe_et_edgv_to_tags\n",
    "}\n",
    "valid_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8ee135c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'POP10',\n",
       " 'step1_consolidado_edif_ensino_total_count',\n",
       " 'step1_consolidado_edif_ensino_name_count',\n",
       " 'step1_consolidado_edif_ensino_name_ratio',\n",
       " 'step1_consolidado_edif_saude_total_count',\n",
       " 'step1_consolidado_edif_saude_name_count',\n",
       " 'step1_consolidado_edif_saude_name_ratio',\n",
       " 'step1_consolidado_edif_desenv_social_total_count',\n",
       " 'step1_consolidado_edif_desenv_social_name_count',\n",
       " 'step1_consolidado_edif_desenv_social_name_ratio',\n",
       " 'step1_consolidado_edif_constr_lazer_total_count',\n",
       " 'step1_consolidado_edif_constr_lazer_name_count',\n",
       " 'step1_consolidado_edif_constr_lazer_name_ratio',\n",
       " 'step1_consolidado_edif_pub_civil_total_count',\n",
       " 'step1_consolidado_edif_pub_civil_name_count',\n",
       " 'step1_consolidado_edif_pub_civil_name_ratio',\n",
       " 'step1_consolidado_edif_turistica_total_count',\n",
       " 'step1_consolidado_edif_turistica_name_count',\n",
       " 'step1_consolidado_edif_turistica_name_ratio',\n",
       " 'step1_consolidado_edif_metro_ferroviaria_total_count',\n",
       " 'step1_consolidado_edif_metro_ferroviaria_name_count',\n",
       " 'step1_consolidado_edif_metro_ferroviaria_name_ratio',\n",
       " 'step2_consolidado_edif_ensino_total_contribs',\n",
       " 'step2_consolidado_edif_ensino_name_contribs',\n",
       " 'step2_consolidado_edif_saude_total_contribs',\n",
       " 'step2_consolidado_edif_saude_name_contribs',\n",
       " 'step2_consolidado_edif_desenv_social_total_contribs',\n",
       " 'step2_consolidado_edif_desenv_social_name_contribs',\n",
       " 'step2_consolidado_edif_constr_lazer_total_contribs',\n",
       " 'step2_consolidado_edif_constr_lazer_name_contribs',\n",
       " 'step2_consolidado_edif_pub_civil_total_contribs',\n",
       " 'step2_consolidado_edif_pub_civil_name_contribs',\n",
       " 'step2_consolidado_edif_turistica_total_contribs',\n",
       " 'step2_consolidado_edif_turistica_name_contribs',\n",
       " 'step2_consolidado_edif_metro_ferroviaria_total_contribs',\n",
       " 'step2_consolidado_edif_metro_ferroviaria_name_contribs',\n",
       " 'step4_consolidado_edif_ensino_name_tagchange',\n",
       " 'step4_consolidado_edif_saude_name_tagchange',\n",
       " 'step4_consolidado_edif_desenv_social_name_tagchange',\n",
       " 'step4_consolidado_edif_constr_lazer_name_tagchange',\n",
       " 'step4_consolidado_edif_pub_civil_name_tagchange',\n",
       " 'step4_consolidado_edif_turistica_name_tagchange',\n",
       " 'step4_consolidado_edif_metro_ferroviaria_name_tagchange',\n",
       " 'step5_consolidado_edif_ensino_users_name',\n",
       " 'step5_consolidado_edif_saude_users_name',\n",
       " 'step5_consolidado_edif_desenv_social_users_name',\n",
       " 'step5_consolidado_edif_constr_lazer_users_name',\n",
       " 'step5_consolidado_edif_pub_civil_users_name',\n",
       " 'step5_consolidado_edif_turistica_users_name',\n",
       " 'step5_consolidado_edif_metro_ferroviaria_users_name',\n",
       " 'step6_consolidado_edif_ensino_contribuicoes_finais',\n",
       " 'step6_consolidado_edif_ensino_sigmoid_rmse',\n",
       " 'step6_consolidado_edif_ensino_sigmoid_pct_erro',\n",
       " 'step6_consolidado_edif_ensino_sigmoid_a',\n",
       " 'step6_consolidado_edif_ensino_sigmoid_b',\n",
       " 'step6_consolidado_edif_ensino_sigmoid_c',\n",
       " 'step6_consolidado_edif_ensino_sigmoid_d',\n",
       " 'step6_consolidado_edif_ensino_inflexao_idx',\n",
       " 'step6_consolidado_edif_ensino_inflexao_data',\n",
       " 'step6_consolidado_edif_ensino_sigmoid_fit_overflow',\n",
       " 'step6_consolidado_edif_ensino_dias_desde_inflexao',\n",
       " 'step6_consolidado_edif_saude_contribuicoes_finais',\n",
       " 'step6_consolidado_edif_saude_sigmoid_rmse',\n",
       " 'step6_consolidado_edif_saude_sigmoid_pct_erro',\n",
       " 'step6_consolidado_edif_saude_sigmoid_a',\n",
       " 'step6_consolidado_edif_saude_sigmoid_b',\n",
       " 'step6_consolidado_edif_saude_sigmoid_c',\n",
       " 'step6_consolidado_edif_saude_sigmoid_d',\n",
       " 'step6_consolidado_edif_saude_inflexao_idx',\n",
       " 'step6_consolidado_edif_saude_inflexao_data',\n",
       " 'step6_consolidado_edif_saude_sigmoid_fit_overflow',\n",
       " 'step6_consolidado_edif_saude_dias_desde_inflexao',\n",
       " 'step6_consolidado_edif_desenv_social_contribuicoes_finais',\n",
       " 'step6_consolidado_edif_desenv_social_sigmoid_rmse',\n",
       " 'step6_consolidado_edif_desenv_social_sigmoid_pct_erro',\n",
       " 'step6_consolidado_edif_desenv_social_sigmoid_a',\n",
       " 'step6_consolidado_edif_desenv_social_sigmoid_b',\n",
       " 'step6_consolidado_edif_desenv_social_sigmoid_c',\n",
       " 'step6_consolidado_edif_desenv_social_sigmoid_d',\n",
       " 'step6_consolidado_edif_desenv_social_inflexao_idx',\n",
       " 'step6_consolidado_edif_desenv_social_inflexao_data',\n",
       " 'step6_consolidado_edif_desenv_social_sigmoid_fit_overflow',\n",
       " 'step6_consolidado_edif_desenv_social_dias_desde_inflexao',\n",
       " 'step6_consolidado_edif_constr_lazer_contribuicoes_finais',\n",
       " 'step6_consolidado_edif_constr_lazer_sigmoid_rmse',\n",
       " 'step6_consolidado_edif_constr_lazer_sigmoid_pct_erro',\n",
       " 'step6_consolidado_edif_constr_lazer_sigmoid_a',\n",
       " 'step6_consolidado_edif_constr_lazer_sigmoid_b',\n",
       " 'step6_consolidado_edif_constr_lazer_sigmoid_c',\n",
       " 'step6_consolidado_edif_constr_lazer_sigmoid_d',\n",
       " 'step6_consolidado_edif_constr_lazer_inflexao_idx',\n",
       " 'step6_consolidado_edif_constr_lazer_inflexao_data',\n",
       " 'step6_consolidado_edif_constr_lazer_sigmoid_fit_overflow',\n",
       " 'step6_consolidado_edif_constr_lazer_dias_desde_inflexao',\n",
       " 'step6_consolidado_edif_pub_civil_contribuicoes_finais',\n",
       " 'step6_consolidado_edif_pub_civil_sigmoid_rmse',\n",
       " 'step6_consolidado_edif_pub_civil_sigmoid_pct_erro',\n",
       " 'step6_consolidado_edif_pub_civil_sigmoid_a',\n",
       " 'step6_consolidado_edif_pub_civil_sigmoid_b',\n",
       " 'step6_consolidado_edif_pub_civil_sigmoid_c',\n",
       " 'step6_consolidado_edif_pub_civil_sigmoid_d',\n",
       " 'step6_consolidado_edif_pub_civil_inflexao_idx',\n",
       " 'step6_consolidado_edif_pub_civil_inflexao_data',\n",
       " 'step6_consolidado_edif_pub_civil_sigmoid_fit_overflow',\n",
       " 'step6_consolidado_edif_pub_civil_dias_desde_inflexao',\n",
       " 'step6_consolidado_edif_turistica_contribuicoes_finais',\n",
       " 'step6_consolidado_edif_turistica_sigmoid_rmse',\n",
       " 'step6_consolidado_edif_turistica_sigmoid_pct_erro',\n",
       " 'step6_consolidado_edif_turistica_sigmoid_a',\n",
       " 'step6_consolidado_edif_turistica_sigmoid_b',\n",
       " 'step6_consolidado_edif_turistica_sigmoid_c',\n",
       " 'step6_consolidado_edif_turistica_sigmoid_d',\n",
       " 'step6_consolidado_edif_turistica_inflexao_idx',\n",
       " 'step6_consolidado_edif_turistica_inflexao_data',\n",
       " 'step6_consolidado_edif_turistica_sigmoid_fit_overflow',\n",
       " 'step6_consolidado_edif_turistica_dias_desde_inflexao',\n",
       " 'step6_consolidado_edif_metro_ferroviaria_contribuicoes_finais',\n",
       " 'step6_consolidado_edif_metro_ferroviaria_sigmoid_rmse',\n",
       " 'step6_consolidado_edif_metro_ferroviaria_sigmoid_pct_erro',\n",
       " 'step6_consolidado_edif_metro_ferroviaria_sigmoid_a',\n",
       " 'step6_consolidado_edif_metro_ferroviaria_sigmoid_b',\n",
       " 'step6_consolidado_edif_metro_ferroviaria_sigmoid_c',\n",
       " 'step6_consolidado_edif_metro_ferroviaria_sigmoid_d',\n",
       " 'step6_consolidado_edif_metro_ferroviaria_inflexao_idx',\n",
       " 'step6_consolidado_edif_metro_ferroviaria_inflexao_data',\n",
       " 'step6_consolidado_edif_metro_ferroviaria_sigmoid_fit_overflow',\n",
       " 'step6_consolidado_edif_metro_ferroviaria_dias_desde_inflexao',\n",
       " 'geometry']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifica se as colunas estão corretas\n",
    "gdf_cells_valid.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4823a98",
   "metadata": {},
   "source": [
    "#### **Request last toponyms and metadata – OHSOME API**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386beb1f",
   "metadata": {},
   "source": [
    "\n",
    "1. Conectar ao PostGIS para filtrar apenas células onde name_ratio > 0 para pelo menos uma classe.\n",
    "\n",
    "2. Pré-filtragem das por células das classe com as tags do dicionário classe_et_edgv_to_tags - aumentar performance.\n",
    "\n",
    "3. Para cada célula e classe com name_ratio > 0:\n",
    "\n",
    "  * Extrair bbox da célula válida;\n",
    "\n",
    "  * Uso do inflexao_data (step6) como início da janela temporal\n",
    "\n",
    "  * Fazer chamada A API OSHOME para para recuperar a contribuição mais recente com name=*\n",
    "    - Endpoint: POST /contributions/latest/geometry;\n",
    "\n",
    "  * ~~'Respeito à data de inflexão (step6_consolidado_{classe}_inflexao_data)~~\n",
    "    * Essa estratégia deixou de ser utilizada, pois foi observado que a contribuição mais recente com name=* pode ter sido feita antes da data da inflexão.\n",
    "    * Nesses casos, usando a inflexão como fromTimestamp, ficamos sem qualquer resultado retornado pela API OHSOME\n",
    "\n",
    "  * Resgatar geometria (pontos) e metadados:\n",
    "    - Metadados: @timestamp, @osmId, tags, name.\n",
    "\n",
    "4. Paralelização por célula\n",
    "\n",
    "5. Log detalhado e consolidação final\n",
    "\n",
    "6. Salvar os resultados em GeoJSON incremental."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afdb47c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados recebidos:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'attribution': {'url': 'https://ohsome.org/copyrights',\n",
       "  'text': '© OpenStreetMap contributors'},\n",
       " 'apiVersion': '1.10.4',\n",
       " 'timeout': 600.0,\n",
       " 'extractRegion': {'spatialExtent': {'type': 'Polygon',\n",
       "   'coordinates': [[[-180.0, -90.0],\n",
       "     [180.0, -90.0],\n",
       "     [180.0, 90.0],\n",
       "     [-180.0, 90.0],\n",
       "     [-180.0, -90.0]]]},\n",
       "  'temporalExtent': {'fromTimestamp': '2007-10-08T00:00:00Z',\n",
       "   'toTimestamp': '2025-07-01T12:00Z'},\n",
       "  'replicationSequenceNumber': 112205}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fetch metadata from the ohsome API\n",
    "# This code fetches metadata from the ohsome API and handles potential JSON decoding errors.\n",
    "import requests\n",
    "\n",
    "URL = 'https://api.ohsome.org/v1/metadata'\n",
    "response = requests.get(URL)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    try:\n",
    "        data = response.json()\n",
    "        print(\"Dados recebidos:\")\n",
    "        display(data)\n",
    "    except ValueError:\n",
    "        print(\"Erro ao decodificar JSON. Conteúdo bruto:\")\n",
    "        display(response.text)\n",
    "else:\n",
    "    display(f\"Erro HTTP {response.status_code}\")\n",
    "    print(\"Resposta:\")\n",
    "    display(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae4b05b",
   "metadata": {},
   "source": [
    "##### Implementação sem módulos externos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b9fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 7: Último topônimo OSM por classe usando a API OHSOME ===\n",
    "# Versão final com paralelização, logs, output GeoJSON e metadados completos\n",
    "\n",
    "# Sem módulos externos (Utils), apenas bibliotecas padrão e geopandas\n",
    "\n",
    "# === Import necessary libraries ===\n",
    "import requests\n",
    "import json\n",
    "from shapely.geometry import shape, mapping\n",
    "import time\n",
    "import math\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from datetime import timedelta\n",
    "import threading\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "# === CONFIGURAÇÕES GERAIS ===\n",
    "output_dir = Path(\"data/output_code1/20cells_tests/step7_latest_name\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "log_path = output_dir / \"log_step7.csv\"\n",
    "ultimo_lote_path = output_dir / \"ultimo_lote_step7.txt\"\n",
    "url_ohsome_latest = \"https://api.ohsome.org/v1/contributions/latest/geometry\"\n",
    "\n",
    "# === INICIALIZAÇÃO DO LOG ===\n",
    "if not log_path.exists():\n",
    "    with open(log_path, 'w', newline='') as f:\n",
    "        csv.writer(f).writerow([\"lote\", \"mensagem\", \"timestamp\"])\n",
    "\n",
    "def log_mensagem(lote, mensagem):\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    with open(log_path, 'a', newline='') as f:\n",
    "        csv.writer(f).writerow([lote, mensagem, timestamp])\n",
    "\n",
    "# === KEEP ALIVE (com controle de término) ===\n",
    "# Flag global para controle\n",
    "keep_alive_running = True\n",
    "\n",
    "def keep_alive():\n",
    "    while keep_alive_running:\n",
    "        time.sleep(300)\n",
    "        print(\"Ainda trabalhando...\")\n",
    "        log_mensagem(\"keep_alive\", \"Ainda trabalhando...\")\n",
    "\n",
    "keep_alive_thread = threading.Thread(target=keep_alive, daemon=True)\n",
    "keep_alive_thread.start()\n",
    "\n",
    "# === FUNÇÃO PARA PROCESSAR UMA CÉLULA ===\n",
    "def processar_ultima_contribuicao(cell_row):\n",
    "    id_celula = cell_row[\"id\"]\n",
    "    bbox = cell_row.geometry.bounds  # (minx, miny, maxx, maxy)\n",
    "    features_resultantes = []\n",
    "\n",
    "    for classe, tags in classe_et_edgv_to_tags.items():\n",
    "        ratio_col = f\"step1_consolidado_{classe}_name_ratio\"\n",
    "        inflexao_col = f\"step6_consolidado_{classe}_inflexao_data\"\n",
    "\n",
    "        if pd.isna(cell_row.get(ratio_col)) or cell_row[ratio_col] <= 0:\n",
    "            continue\n",
    "\n",
    "        data_inicio_str = cell_row.get(inflexao_col) # Uso do inflexao_data como início da janela temporal\n",
    "        if not isinstance(data_inicio_str, str) or data_inicio_str.strip() == \"\" or data_inicio_str.lower() == \"none\":\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            data_inicio = pd.to_datetime(data_inicio_str, errors=\"coerce\")\n",
    "            if pd.isna(data_inicio):\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            log_mensagem(id_celula, f\"[ERRO] Conversão de data inflexão inválida: {data_inicio_str} - {e}\")\n",
    "            continue\n",
    "\n",
    "        data_fim = pd.Timestamp(\"2025-04-06T13:00Z\").strftime(\"%Y-%m-%d\") # data_fim fixa de acordo com API metadata ('temporalExtent')\n",
    "        data_inicio_str = data_inicio.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        for tag, value in tags:\n",
    "            payload = {\n",
    "                \"bboxes\": f\"{bbox[0]},{bbox[1]},{bbox[2]},{bbox[3]}\",\n",
    "                \"time\": f\"{data_inicio_str},{data_fim}\",\n",
    "                \"filter\": f\"{tag}={value} and name=*\",\n",
    "                \"properties\": \"metadata,tags\",\n",
    "                \"clipGeometry\": \"false\"\n",
    "            }\n",
    "\n",
    "            try:\n",
    "                response = requests.post(url_ohsome_latest, data=payload)\n",
    "                \n",
    "                print(f\"[DEBUG] Célula: {id_celula}, Classe: {classe}, Tag={tag}, Value={value}\")\n",
    "                print(f\"[DEBUG] Payload: {json.dumps(payload)}\")\n",
    "                print(f\"[DEBUG] Status Code: {response.status_code}\")\n",
    "                print(f\"[DEBUG] Response Text: {response.text[:300]}\")  # apenas os primeiros 300 chars\n",
    "\n",
    "                response.raise_for_status()\n",
    "                dados = response.json()\n",
    "\n",
    "                for feat in dados.get(\"features\", []):\n",
    "                    geom_data = feat.get(\"geometry\")\n",
    "                    props = feat.get(\"properties\", {})\n",
    "\n",
    "                    if geom_data is None:\n",
    "                        continue\n",
    "\n",
    "                    geom = shape(geom_data)\n",
    "                    if geom.geom_type in [\"Polygon\", \"MultiPolygon\"]:\n",
    "                        geom = geom.centroid\n",
    "\n",
    "                    props_clean = {\n",
    "                        \"id_celula\": id_celula,\n",
    "                        \"classe\": classe,\n",
    "                        \"tag\": tag,\n",
    "                        \"value\": value,\n",
    "                        **props\n",
    "                    }\n",
    "\n",
    "                    features_resultantes.append({\n",
    "                        \"type\": \"Feature\",\n",
    "                        \"geometry\": mapping(geom),\n",
    "                        \"properties\": props_clean\n",
    "                    })\n",
    "\n",
    "            except Exception as e:\n",
    "                log_mensagem(id_celula, f\"[ERRO OHSOME {classe}] {tag}={value}: {str(e)}\")\n",
    "\n",
    "    return features_resultantes\n",
    "\n",
    "try:\n",
    "    # === EXECUÇÃO EM LOTE ===\n",
    "    ultimo_lote = 0\n",
    "    if ultimo_lote_path.exists():\n",
    "        with open(ultimo_lote_path, 'r') as f:\n",
    "            ultimo_lote = int(f.read().strip())\n",
    "\n",
    "    lote_size = 20\n",
    "    total_lotes = math.ceil(len(gdf_cells_valid) / lote_size)\n",
    "\n",
    "    for lote_index in range(ultimo_lote, total_lotes):\n",
    "        start_time = time.time()\n",
    "        features_final = []\n",
    "\n",
    "        subset = gdf_cells_valid.iloc[lote_index * lote_size: (lote_index + 1) * lote_size]\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "            futures = [executor.submit(processar_ultima_contribuicao, row) for _, row in subset.iterrows()]\n",
    "            for future in tqdm(as_completed(futures), total=len(futures), desc=f\"Lote {lote_index + 1} (Step 7)\"):\n",
    "                try:\n",
    "                    features_final.extend(future.result())\n",
    "                except Exception as e:\n",
    "                    log_mensagem(lote_index + 1, f\"[FALHA GERAL]: {e}\")\n",
    "\n",
    "        # Salva lote em GeoJSON\n",
    "        fc = {\"type\": \"FeatureCollection\", \"features\": features_final}\n",
    "        out_path = output_dir / f\"step7_lote{lote_index + 1}.geojson\"\n",
    "        with open(out_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(fc, f)\n",
    "        log_mensagem(lote_index + 1, f\"SALVO {out_path.name}\")\n",
    "\n",
    "        # Atualiza consolidação incremental\n",
    "        arquivos = sorted(output_dir.glob(\"step7_lote*.geojson\"))\n",
    "        todas_features = []\n",
    "        for arquivo in arquivos:\n",
    "            with open(arquivo, 'r', encoding='utf-8') as f:\n",
    "                fc_parcial = json.load(f)\n",
    "                todas_features.extend(fc_parcial['features'])\n",
    "\n",
    "        final_fc = {\"type\": \"FeatureCollection\", \"features\": todas_features}\n",
    "        with open(output_dir / \"step7_consolidado.geojson\", 'w', encoding='utf-8') as f:\n",
    "            json.dump(final_fc, f)\n",
    "        log_mensagem(lote_index + 1, \"CONSOLIDADO atualizado\")\n",
    "\n",
    "        with open(ultimo_lote_path, 'w') as f:\n",
    "            f.write(str(lote_index + 1))\n",
    "\n",
    "        tempo_msg = f\"Tempo lote {lote_index + 1}: {str(timedelta(seconds=int(time.time() - start_time)))}\"\n",
    "        print(tempo_msg)\n",
    "        log_mensagem(lote_index + 1, tempo_msg)\n",
    "\n",
    "    print(\"Step 7 (último topônimo por classe) finalizado com sucesso.\")\n",
    "    log_mensagem(\"step7\", \"Processamento finalizado\")\n",
    "\n",
    "finally:\n",
    "    keep_alive_running = False\n",
    "    keep_alive_thread.join(timeout=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44a0c0d",
   "metadata": {},
   "source": [
    "##### Implementação com módulos externos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d122633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 7 (OHSOME API) ===\n",
    "# Com módulos utils e processar_com_ohsome\n",
    "\n",
    "# === Import necessary libraries and modules ===\n",
    "from src.utils import init_log, start_keep_alive, log_mensagem, consolidar_geojson\n",
    "from src.processar_com_ohsome import processar_com_ohsome\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from datetime import timedelta\n",
    "import json, math, time\n",
    "\n",
    "# === CONFIGURAÇÕES GERAIS ===\n",
    "output_dir = Path(\"results/2_toponyms_retrieval/step7_latest_name_ohsome/v2_comp/step7_latest_name_ohsome\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "log_path = output_dir / \"log_step7_ohsome.csv\"\n",
    "ultimo_lote_path = output_dir / \"ultimo_lote_step7_ohsome.txt\"\n",
    "\n",
    "# === LOG E KEEP ALIVE ===\n",
    "# Flag global para controle\n",
    "\n",
    "init_log(log_path)\n",
    "keep_alive_flag = {\"running\": True}\n",
    "keep_alive_thread = start_keep_alive(log_path, keep_alive_flag)\n",
    "\n",
    "# === EXECUÇÃO EM LOTE ===\n",
    "try:\n",
    "    ultimo_lote = int(ultimo_lote_path.read_text().strip()) if ultimo_lote_path.exists() else 0\n",
    "    lote_size = 20\n",
    "    total_lotes = math.ceil(len(gdf_cells_valid) / lote_size)\n",
    "\n",
    "    for lote_index in range(ultimo_lote, total_lotes):\n",
    "        start_time = time.time()\n",
    "        features_final = []\n",
    "        subset = gdf_cells_valid.iloc[lote_index * lote_size: (lote_index + 1) * lote_size]\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "            futures = [\n",
    "                executor.submit(processar_com_ohsome, row, classe_et_edgv_to_tags, log_mensagem, log_path)\n",
    "                for _, row in subset.iterrows()\n",
    "            ]\n",
    "            for future in tqdm(as_completed(futures), total=len(futures), desc=f\"Lote {lote_index + 1} (Step 7 OHSOME)\"):\n",
    "                try:\n",
    "                    features_final.extend(future.result())\n",
    "                except Exception as e:\n",
    "                    log_mensagem(log_path, lote_index + 1, f\"[FALHA GERAL]: {e}\")\n",
    "\n",
    "        out_path = output_dir / f\"step7_lote{lote_index + 1}.geojson\"\n",
    "        with open(out_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump({\"type\": \"FeatureCollection\", \"features\": features_final}, f)\n",
    "        log_mensagem(log_path, lote_index + 1, f\"SALVO {out_path.name}\")\n",
    "\n",
    "        total_feats = consolidar_geojson(output_dir, \"step7_lote*.geojson\", \"step7_consolidado_oshome.geojson\")\n",
    "        log_mensagem(log_path, lote_index + 1, f\"CONSOLIDADO atualizado: {total_feats} features\")\n",
    "\n",
    "        ultimo_lote_path.write_text(str(lote_index + 1))\n",
    "        print(f\"Lote {lote_index + 1} concluído em {str(timedelta(seconds=int(time.time() - start_time)))}\")\n",
    "\n",
    "    print(\"Step 7 (OHSOME) finalizado com sucesso.\")\n",
    "    log_mensagem(log_path, \"final\", \"Processamento concluído\")\n",
    "\n",
    "finally:\n",
    "    keep_alive_flag[\"running\"] = False\n",
    "    keep_alive_thread.join(timeout=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f06f86",
   "metadata": {},
   "source": [
    "#### **Request last toponyms and metadata – Overpass API**\n",
    "\n",
    " * [Overpass API](https://wiki.openstreetmap.org/wiki/Overpass_API)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54578457",
   "metadata": {},
   "source": [
    "##### Implementação sem módulos externos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e02a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 7: Último topônimo OSM por classe (via Overpass API) ===\n",
    "# Sem módulo utils\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time, threading, math, json, csv, glob\n",
    "import pandas as pd\n",
    "\n",
    "# === CONFIGURAÇÕES GERAIS ===\n",
    "output_dir = Path(\"data/output_code1/step7_latest_name_overpass\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "log_path = output_dir / \"log_step7_overpass.csv\"\n",
    "ultimo_lote_path = output_dir / \"ultimo_lote_step7_overpass.txt\"\n",
    "\n",
    "# === INICIALIZAÇÃO DO LOG ===\n",
    "if not log_path.exists():\n",
    "    with open(log_path, 'w', newline='') as f:\n",
    "        csv.writer(f).writerow([\"lote\", \"mensagem\", \"timestamp\"])\n",
    "\n",
    "def log_mensagem(lote, mensagem):\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    with open(log_path, 'a', newline='') as f:\n",
    "        csv.writer(f).writerow([lote, mensagem, timestamp])\n",
    "\n",
    "# === KEEP ALIVE (com controle de término) ===\n",
    "keep_alive_running = True\n",
    "def keep_alive():\n",
    "    while keep_alive_running:\n",
    "        time.sleep(300)\n",
    "        print(\"Ainda trabalhando...\")\n",
    "        log_mensagem(\"keep_alive\", \"Ainda trabalhando...\")\n",
    "\n",
    "keep_alive_thread = threading.Thread(target=keep_alive, daemon=True)\n",
    "keep_alive_thread.start()\n",
    "\n",
    "# === EXECUÇÃO EM LOTE USANDO OVERPASS ===\n",
    "try:\n",
    "    ultimo_lote = 0\n",
    "    if ultimo_lote_path.exists():\n",
    "        with open(ultimo_lote_path, 'r') as f:\n",
    "            ultimo_lote = int(f.read().strip())\n",
    "\n",
    "    lote_size = 20\n",
    "    total_lotes = math.ceil(len(gdf_cells_valid) / lote_size)\n",
    "\n",
    "    for lote_index in range(ultimo_lote, total_lotes):\n",
    "        start_time = time.time()\n",
    "        features_final = []\n",
    "\n",
    "        subset = gdf_cells_valid.iloc[lote_index * lote_size: (lote_index + 1) * lote_size]\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "            futures = [executor.submit(processar_com_overpass, row, classe_et_edgv_to_tags, log_mensagem) for _, row in subset.iterrows()]\n",
    "            for future in as_completed(futures):\n",
    "                try:\n",
    "                    features_final.extend(future.result())\n",
    "                except Exception as e:\n",
    "                    log_mensagem(lote_index + 1, f\"[FALHA GERAL]: {e}\")\n",
    "\n",
    "        # Salva lote em GeoJSON\n",
    "        fc = {\"type\": \"FeatureCollection\", \"features\": features_final}\n",
    "        out_path = output_dir / f\"step7_lote{lote_index + 1}.geojson\"\n",
    "        with open(out_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(fc, f)\n",
    "        log_mensagem(lote_index + 1, f\"SALVO {out_path.name}\")\n",
    "\n",
    "        # Atualiza consolidação incremental\n",
    "        arquivos = sorted(output_dir.glob(\"step7_lote*.geojson\"))\n",
    "        todas_features = []\n",
    "        for arquivo in arquivos:\n",
    "            with open(arquivo, 'r', encoding='utf-8') as f:\n",
    "                fc_parcial = json.load(f)\n",
    "                todas_features.extend(fc_parcial['features'])\n",
    "\n",
    "        final_fc = {\"type\": \"FeatureCollection\", \"features\": todas_features}\n",
    "        with open(output_dir / \"step7_consolidado.geojson\", 'w', encoding='utf-8') as f:\n",
    "            json.dump(final_fc, f)\n",
    "        log_mensagem(lote_index + 1, \"CONSOLIDADO atualizado\")\n",
    "\n",
    "        with open(ultimo_lote_path, 'w') as f:\n",
    "            f.write(str(lote_index + 1))\n",
    "\n",
    "        tempo_msg = f\"Tempo lote {lote_index + 1}: {str(timedelta(seconds=int(time.time() - start_time)))}\"\n",
    "        print(tempo_msg)\n",
    "        log_mensagem(lote_index + 1, tempo_msg)\n",
    "\n",
    "    print(\"Step 7 (último topônimo por classe - Overpass) finalizado com sucesso.\")\n",
    "    log_mensagem(\"step7_overpass\", \"Processamento finalizado\")\n",
    "\n",
    "finally:\n",
    "    keep_alive_running = False\n",
    "    keep_alive_thread.join(timeout=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93247bc3",
   "metadata": {},
   "source": [
    "##### Implementação com módulos externos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c48a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 7 (Overpass API) ===\n",
    "# Com módulos utils e processar_com_overpass\n",
    "\n",
    "from src.utils import init_log, start_keep_alive, log_mensagem, consolidar_geojson\n",
    "from src.processar_com_overpass import processar_com_overpass\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import math, json, time\n",
    "\n",
    "# === CONFIGURAÇÃO ===\n",
    "output_dir = Path(\"data/output_code1/step7_latest_name_overpass\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "log_path = output_dir / \"log_step7_overpass.csv\"\n",
    "ultimo_lote_path = output_dir / \"ultimo_lote_step7_overpass.txt\"\n",
    "\n",
    "# === LOG E KEEP ALIVE ===\n",
    "init_log(log_path)\n",
    "keep_alive_flag = {\"running\": True}\n",
    "keep_alive_thread = start_keep_alive(log_path, keep_alive_flag)\n",
    "\n",
    "# === EXECUÇÃO EM LOTE ===\n",
    "try:\n",
    "    ultimo_lote = int(ultimo_lote_path.read_text().strip()) if ultimo_lote_path.exists() else 0\n",
    "    lote_size = 20\n",
    "    total_lotes = math.ceil(len(gdf_cells_valid) / lote_size)\n",
    "\n",
    "    for lote_index in range(ultimo_lote, total_lotes):\n",
    "        start_time = time.time()\n",
    "        features_final = []\n",
    "        subset = gdf_cells_valid.iloc[lote_index * lote_size: (lote_index + 1) * lote_size]\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "            futures = [\n",
    "                executor.submit(processar_com_overpass, row, classe_et_edgv_to_tags, log_mensagem, log_path)\n",
    "                for _, row in subset.iterrows()\n",
    "            ]\n",
    "            for future in tqdm(as_completed(futures), total=len(futures), desc=f\"Lote {lote_index + 1} (Step 7 Overpass)\"):\n",
    "                try:\n",
    "                    features_final.extend(future.result())\n",
    "                except Exception as e:\n",
    "                    log_mensagem(log_path, lote_index + 1, f\"[FALHA GERAL]: {e}\")\n",
    "\n",
    "        # Salva lote\n",
    "        out_path = output_dir / f\"step7_lote{lote_index + 1}.geojson\"\n",
    "        with open(out_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump({\"type\": \"FeatureCollection\", \"features\": features_final}, f)\n",
    "        log_mensagem(log_path, lote_index + 1, f\"SALVO {out_path.name}\")\n",
    "\n",
    "        # Consolida incremental\n",
    "        total_feats = consolidar_geojson(output_dir, \"step7_lote*.geojson\", \"step7_consolidado.geojson\")\n",
    "        log_mensagem(log_path, lote_index + 1, f\"CONSOLIDADO atualizado: {total_feats} features\")\n",
    "\n",
    "        # Atualiza lote\n",
    "        ultimo_lote_path.write_text(str(lote_index + 1))\n",
    "        print(f\"Lote {lote_index + 1} concluído em {str(timedelta(seconds=int(time.time() - start_time)))}\")\n",
    "\n",
    "    print(\"Step 7 (Overpass) finalizado com sucesso.\")\n",
    "    log_mensagem(log_path, \"final\", \"Processamento concluído\")\n",
    "\n",
    "finally:\n",
    "    keep_alive_flag[\"running\"] = False\n",
    "    keep_alive_thread.join(timeout=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c41c17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DEBUG MANUAL - PROCESSAR UMA CELULA ===\n",
    "\n",
    "# Rodar debug manual com apenas uma célula\n",
    "test_row = gdf_cells_valid.iloc[0]\n",
    "features = processar_com_overpass.processar_com_overpass(test_row, classe_et_edgv_to_tags, log_mensagem, log_path)\n",
    "\n",
    "print(json.dumps(features, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61257e6f",
   "metadata": {},
   "source": [
    "#### Deduplicação de pontos com topônimos extraídos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90245e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load again the GeoDataFrame from step 7 the consolidated GeoJSON file\n",
    "import geopandas as gpd\n",
    "gdf_step7 = gpd.read_file('results/2_toponyms_retrieval/step7_latest_name_ohsome/step7_consolidado_ohsome.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a55c69fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_celula</th>\n",
       "      <th>classe</th>\n",
       "      <th>tag</th>\n",
       "      <th>value</th>\n",
       "      <th>@changesetId</th>\n",
       "      <th>@contributionChangesetId</th>\n",
       "      <th>@creation</th>\n",
       "      <th>@osmId</th>\n",
       "      <th>@osmType</th>\n",
       "      <th>@timestamp</th>\n",
       "      <th>...</th>\n",
       "      <th>indoor</th>\n",
       "      <th>building:use</th>\n",
       "      <th>training</th>\n",
       "      <th>subject:wikidata</th>\n",
       "      <th>subject:wikipedia</th>\n",
       "      <th>payment:account_cards</th>\n",
       "      <th>shop</th>\n",
       "      <th>int_name</th>\n",
       "      <th>nohousenumber</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200ME60346N90864</td>\n",
       "      <td>edif_ensino</td>\n",
       "      <td>amenity</td>\n",
       "      <td>school</td>\n",
       "      <td>56647215</td>\n",
       "      <td>56647215</td>\n",
       "      <td>True</td>\n",
       "      <td>way/172871823</td>\n",
       "      <td>way</td>\n",
       "      <td>2018-02-24 22:13:53+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (-44.05395 -19.99415)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200ME60338N90882</td>\n",
       "      <td>edif_constr_lazer</td>\n",
       "      <td>leisure</td>\n",
       "      <td>park</td>\n",
       "      <td>105601725</td>\n",
       "      <td>105601725</td>\n",
       "      <td>True</td>\n",
       "      <td>way/511117205</td>\n",
       "      <td>way</td>\n",
       "      <td>2021-05-31 06:56:23+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (-44.06307 -19.97691)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200ME60348N90864</td>\n",
       "      <td>edif_constr_lazer</td>\n",
       "      <td>leisure</td>\n",
       "      <td>park</td>\n",
       "      <td>12479899</td>\n",
       "      <td>12479899</td>\n",
       "      <td>True</td>\n",
       "      <td>way/172871822</td>\n",
       "      <td>way</td>\n",
       "      <td>2012-07-25 02:06:21+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (-44.05274 -19.99391)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200ME60344N90866</td>\n",
       "      <td>edif_constr_lazer</td>\n",
       "      <td>leisure</td>\n",
       "      <td>park</td>\n",
       "      <td>12479899</td>\n",
       "      <td>96238688</td>\n",
       "      <td>None</td>\n",
       "      <td>way/172873826</td>\n",
       "      <td>way</td>\n",
       "      <td>2020-12-22 07:32:20+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (-44.05562 -19.99122)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200ME60346N90862</td>\n",
       "      <td>edif_ensino</td>\n",
       "      <td>amenity</td>\n",
       "      <td>school</td>\n",
       "      <td>56647215</td>\n",
       "      <td>56647215</td>\n",
       "      <td>True</td>\n",
       "      <td>way/172871823</td>\n",
       "      <td>way</td>\n",
       "      <td>2018-02-24 22:13:53+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (-44.05395 -19.99415)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 191 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id_celula             classe      tag   value  @changesetId  \\\n",
       "0  200ME60346N90864        edif_ensino  amenity  school      56647215   \n",
       "1  200ME60338N90882  edif_constr_lazer  leisure    park     105601725   \n",
       "2  200ME60348N90864  edif_constr_lazer  leisure    park      12479899   \n",
       "3  200ME60344N90866  edif_constr_lazer  leisure    park      12479899   \n",
       "4  200ME60346N90862        edif_ensino  amenity  school      56647215   \n",
       "\n",
       "   @contributionChangesetId @creation         @osmId @osmType  \\\n",
       "0                  56647215      True  way/172871823      way   \n",
       "1                 105601725      True  way/511117205      way   \n",
       "2                  12479899      True  way/172871822      way   \n",
       "3                  96238688      None  way/172873826      way   \n",
       "4                  56647215      True  way/172871823      way   \n",
       "\n",
       "                 @timestamp  ...  indoor building:use training  \\\n",
       "0 2018-02-24 22:13:53+00:00  ...    None         None     None   \n",
       "1 2021-05-31 06:56:23+00:00  ...    None         None     None   \n",
       "2 2012-07-25 02:06:21+00:00  ...    None         None     None   \n",
       "3 2020-12-22 07:32:20+00:00  ...    None         None     None   \n",
       "4 2018-02-24 22:13:53+00:00  ...    None         None     None   \n",
       "\n",
       "  subject:wikidata subject:wikipedia payment:account_cards  shop int_name  \\\n",
       "0             None              None                  None  None     None   \n",
       "1             None              None                  None  None     None   \n",
       "2             None              None                  None  None     None   \n",
       "3             None              None                  None  None     None   \n",
       "4             None              None                  None  None     None   \n",
       "\n",
       "  nohousenumber                     geometry  \n",
       "0          None  POINT (-44.05395 -19.99415)  \n",
       "1          None  POINT (-44.06307 -19.97691)  \n",
       "2          None  POINT (-44.05274 -19.99391)  \n",
       "3          None  POINT (-44.05562 -19.99122)  \n",
       "4          None  POINT (-44.05395 -19.99415)  \n",
       "\n",
       "[5 rows x 191 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(gdf_step7.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f727dceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 3578\n"
     ]
    }
   ],
   "source": [
    "# Check the number of features in the GeoDataFrame\n",
    "print(f\"Number of features: {len(gdf_step7)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "270dc811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/93/jp7gz1rj0sg95pqlydn2yhk40000gn/T/ipykernel_35682/4031892776.py:34: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(selecionar_ponto_preferido)\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# Corrigir tipos\n",
    "gdf_step7[\"@version\"] = pd.to_numeric(gdf_step7[\"@version\"], errors='coerce')\n",
    "\n",
    "# Agrupar por geometrias duplicadas\n",
    "def selecionar_ponto_preferido(grupo):\n",
    "    \"\"\"\n",
    "    Seleciona o ponto mais apropriado entre duplicatas reais (mesma geometry, timestamp e versão)\n",
    "    Prioriza o ponto cujo id_celula contém realmente o ponto.\n",
    "    \"\"\"\n",
    "    if len(grupo) == 1:\n",
    "        return grupo\n",
    "\n",
    "    # Verifica espacialmente qual ponto realmente está dentro da sua célula\n",
    "    for idx, row in grupo.iterrows():\n",
    "        id_celula = row[\"id_celula\"]\n",
    "        ponto = row[\"geometry\"]\n",
    "        try:\n",
    "            poligono = gdf_cells_valid.loc[id_celula, \"geometry\"]\n",
    "            if ponto.within(poligono):\n",
    "                return pd.DataFrame([row])\n",
    "        except KeyError:\n",
    "            continue  # id_celula não encontrado\n",
    "\n",
    "    # Se nenhum \"bate\" espacialmente, mantém o primeiro\n",
    "    return grupo.iloc[[0]]\n",
    "\n",
    "# Aplicar deduplicação por geometria\n",
    "gdf_filtrado = (\n",
    "    gdf_step7.sort_values(by=[\"@timestamp\", \"@version\"], ascending=[False, False])\n",
    "       .groupby([\"geometry\", \"@timestamp\", \"@version\"], group_keys=False)\n",
    "       .apply(selecionar_ponto_preferido)\n",
    "       .reset_index(drop=True)\n",
    ")\n",
    "# Reconstrói como GeoDataFrame\n",
    "gdf_filtrado = gpd.GeoDataFrame(gdf_filtrado, geometry=\"geometry\", crs=gdf_step7.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c069580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features after filtering: 1626\n"
     ]
    }
   ],
   "source": [
    "# Number of features after filtering\n",
    "print(f\"Number of features after filtering: {len(gdf_filtrado)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdf66215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id_celula',\n",
       " 'classe',\n",
       " 'tag',\n",
       " 'value',\n",
       " '@changesetId',\n",
       " '@contributionChangesetId',\n",
       " '@creation',\n",
       " '@osmId',\n",
       " '@osmType',\n",
       " '@timestamp',\n",
       " '@version',\n",
       " 'addr:housenumber',\n",
       " 'addr:street',\n",
       " 'amenity',\n",
       " 'contact:phone',\n",
       " 'name',\n",
       " 'operator',\n",
       " 'leisure',\n",
       " '@geometryChange',\n",
       " '@tagChange',\n",
       " 'addr:city',\n",
       " 'addr:postcode',\n",
       " 'addr:suburb',\n",
       " 'short_name',\n",
       " 'sport',\n",
       " 'type',\n",
       " 'healthcare',\n",
       " 'healthcare:speciality',\n",
       " 'operator:type',\n",
       " 'phone',\n",
       " 'tourism',\n",
       " 'opening_hours',\n",
       " 'landuse',\n",
       " 'natural',\n",
       " 'wheelchair',\n",
       " 'admin_level',\n",
       " 'source',\n",
       " 'building',\n",
       " 'dog',\n",
       " 'email',\n",
       " 'fixme',\n",
       " 'phone_1',\n",
       " 'alt_name',\n",
       " 'check_date',\n",
       " 'brand',\n",
       " 'brand:wikidata',\n",
       " 'dispensing',\n",
       " 'internet_access',\n",
       " 'internet_access:fee',\n",
       " 'public_transport',\n",
       " 'railway',\n",
       " 'station',\n",
       " 'subway',\n",
       " 'wikidata',\n",
       " 'garden:type',\n",
       " 'theatre:genre',\n",
       " 'website',\n",
       " 'brand:wikipedia',\n",
       " 'surface',\n",
       " 'school',\n",
       " 'emergency',\n",
       " 'government',\n",
       " 'office',\n",
       " 'smoking',\n",
       " 'building:levels',\n",
       " 'height',\n",
       " 'grades',\n",
       " 'religion',\n",
       " 'level',\n",
       " 'drive_through',\n",
       " 'payment:cash',\n",
       " 'payment:credit_cards',\n",
       " 'payment:debit_cards',\n",
       " 'man_made',\n",
       " 'highway',\n",
       " 'ref:CNES',\n",
       " 'note:pt',\n",
       " 'name:pt',\n",
       " 'toilets:wheelchair',\n",
       " 'network',\n",
       " 'layer',\n",
       " 'ref:PBH',\n",
       " 'barrier',\n",
       " 'social_facility',\n",
       " 'preschool',\n",
       " 'source:name',\n",
       " 'url',\n",
       " 'ref',\n",
       " 'addr:country',\n",
       " 'description',\n",
       " 'loc_name',\n",
       " 'wikimedia_commons',\n",
       " 'wikipedia',\n",
       " 'direction',\n",
       " 'contact:email',\n",
       " 'square',\n",
       " 'addr:place',\n",
       " 'addr:state',\n",
       " 'operator:short',\n",
       " 'operator:wikidata',\n",
       " 'old_name',\n",
       " 'social_facility:for',\n",
       " 'name:en',\n",
       " 'official_name',\n",
       " 'official_name:en',\n",
       " 'bus',\n",
       " '2016olympicgames',\n",
       " 'nickname',\n",
       " 'contact:facebook',\n",
       " 'contact:instagram',\n",
       " 'contact:twitter',\n",
       " 'contact:website',\n",
       " 'contact:youtube',\n",
       " 'museum',\n",
       " 'noexit',\n",
       " 'pound',\n",
       " 'boundary',\n",
       " 'internet_access:ssid',\n",
       " 'access',\n",
       " 'place',\n",
       " 'ownership',\n",
       " 'capacity',\n",
       " 'denomination',\n",
       " 'image',\n",
       " 'polling_station',\n",
       " 'start_date',\n",
       " 'footway',\n",
       " 'contact:whatsapp',\n",
       " 'addr:housename',\n",
       " 'note',\n",
       " 'crás',\n",
       " 'opening_hours:covid19',\n",
       " 'ref:vatin',\n",
       " 'building:levels:underground',\n",
       " 'toilet',\n",
       " 'branch',\n",
       " 'faculty',\n",
       " 'artist_name',\n",
       " 'artwork_type',\n",
       " 'roof:levels',\n",
       " 'maxspeed',\n",
       " 'fee',\n",
       " 'source:amenity',\n",
       " 'building:name',\n",
       " 'charge',\n",
       " 'mapillary',\n",
       " 'fax',\n",
       " 'related_law',\n",
       " 'service',\n",
       " 'currency:XBT',\n",
       " 'payment:PIX',\n",
       " 'payment:lightning',\n",
       " 'payment:lightning_contactless',\n",
       " 'payment:onchain',\n",
       " 'material',\n",
       " 'sidewalk',\n",
       " 'historic',\n",
       " 'source:alt_name',\n",
       " 'operator:ref:vatin',\n",
       " 'name:es',\n",
       " 'designation',\n",
       " 'room',\n",
       " 'building:min_level',\n",
       " 'ele',\n",
       " 'pets_allowed',\n",
       " 'drinking_water',\n",
       " 'lit',\n",
       " 'covered',\n",
       " 'source:addr:street',\n",
       " 'payment:coins',\n",
       " 'memorial',\n",
       " 'pharmacy',\n",
       " 'inscription',\n",
       " 'train',\n",
       " 'contact:flickr',\n",
       " 'contact:issu',\n",
       " 'wikipedia:pt',\n",
       " 'air_conditioning',\n",
       " 'area',\n",
       " 'addr:province',\n",
       " 'indoor',\n",
       " 'building:use',\n",
       " 'training',\n",
       " 'subject:wikidata',\n",
       " 'subject:wikipedia',\n",
       " 'payment:account_cards',\n",
       " 'shop',\n",
       " 'int_name',\n",
       " 'nohousenumber',\n",
       " 'geometry']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_filtrado.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f72462a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_filtrado = gdf_filtrado.drop(columns=[\"payment:pix\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1a2633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered GeoDataFrame to a new GeoPackage file\n",
    "output_gpkg = 'results/2_toponyms_retrieval/step7_latest_name_ohsome/step7_consolidado_ohsome_filtrado.gpkg'\n",
    "gdf_filtrado.to_file(output_gpkg, driver='GPKG', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1fe7c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered GeoDataFrame to a new GeoJSON file\n",
    "output_path = 'results/2_toponyms_retrieval/step7_latest_name_ohsome/step7_consolidado_ohsome_filtrado.geojson'\n",
    "gdf_filtrado.to_file(output_path, driver='GeoJSON', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a938b8f7",
   "metadata": {},
   "source": [
    "#### PostGIS - Close the database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c11755da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexão com o banco de dados fechada.\n"
     ]
    }
   ],
   "source": [
    "# Close the database connection\n",
    "if conn and conn.closed == 0:\n",
    "    # conexão ainda aberta\n",
    "    with conn.cursor() as cur:\n",
    "        ...\n",
    "        cur.close()\n",
    "    conn.close()\n",
    "    print(\"Conexão com o banco de dados fechada.\")\n",
    "else:\n",
    "    print(\"Conexão com o banco de dados já estava fechada ou não foi estabelecida.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-DScPythonGeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
